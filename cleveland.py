# -*- coding: utf-8 -*-
"""Cleveland.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14pvNI-RtsgYxWYwKhJS2ngoUuNHks5is
"""

import pandas as pd

# Load the dataset
va = pd.read_csv('processed.cleveland.csv')

header = 'age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'

va.columns = header

# Remove rows with '?' in any column (already replaced with NaN in the cleaning step)
va_cleaned_no_missing = va.replace('?', pd.NA).dropna()

# Convert all columns in the dataset to numeric, coercing errors
va_numeric = va_cleaned_no_missing.apply(pd.to_numeric, errors='coerce')


# Identifying and removing outliers using the IQR method

def remove_outliers(df, columns):
    cleaned_data = df.copy()
    for column in columns:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Filter outliers
        cleaned_data = cleaned_data[(cleaned_data[column] >= lower_bound) & (cleaned_data[column] <= upper_bound)]
    return cleaned_data


# Update the list of columns for outlier detection to include only continuous variables
continuous_columns = ['age', 'trestbps', 'oldpeak']

cleaned_data_va = remove_outliers(va_numeric, continuous_columns)

# Comparing the original data with the cleaned data
cleaned_shape_va = cleaned_data_va.shape

print(va_numeric.shape, cleaned_shape_va)

!pip install ctgan
!pip install table_evaluator

categorical_features = ['sex', 'cp', 'restecg', 'exang', 'slope', 'ca', 'thal', 'num']

from ctgan import CTGAN
ctgan = CTGAN(verbose=True)
ctgan.fit(cleaned_data_va, categorical_features, epochs = 2000)

samples = ctgan.sample(10000)
print(samples)


cleaned_data1 = remove_outliers(samples, continuous_columns)

# Comparing the original data with the cleaned data
original_shape1 = samples.shape
cleaned_shape1 = cleaned_data1.shape

print(original_shape1, cleaned_shape1)

from table_evaluator import TableEvaluator

print(cleaned_data_va.shape, cleaned_data1.shape)
table_evaluator = TableEvaluator(cleaned_data_va, cleaned_data1, cat_cols= categorical_features)

table_evaluator.visual_evaluation()

# Splitting the data into features (X) and target (y)
X = cleaned_data1.drop('num', axis=1)
y = cleaned_data1['num']

y_not_zero = y > 0
y[y_not_zero] = 1


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import numpy as np

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Optionally, scale the data if PCA or your model requires it
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


from sklearn.decomposition import PCA


# Assuming scaled_data is defined and correctly scaled
# If scaled_data is not defined, replace it with X_scaled or your scaled dataset variable

# Applying PCA
pca = PCA(n_components=6)
X_train_pca = pca.fit_transform(X_train_scaled)

# Transform the scaled test data using the same PCA
X_test_pca = pca.transform(X_test_scaled)


# Reshaping the data for 1D-CNN input
X1_train = X_train_pca.reshape(X_train_pca.shape[0], X_train_pca.shape[1], 1)
X1_test = X_test_pca.reshape(X_test_pca.shape[0], X_test_pca.shape[1], 1)

X1_train.shape, X1_test.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout


# Define the 1D-CNN model
model = Sequential([
    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(6, 1)),
    MaxPooling1D(pool_size=1),
    Dropout(0.2),
    Conv1D(filters=128, kernel_size=2, activation='relu'),
    Dropout(0.2),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['accuracy'])

# Train the model
history = model.fit(X1_train, y_train, epochs=20, validation_split=0.2, batch_size=15)

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(X1_test, y_test)
print(f'Test Accuracy: {test_acc*100:.2f}%')

!pip install pytorch-tabnet
from pytorch_tabnet.tab_model import TabNetClassifier
import torch

# Set device to GPU if available, else CPU
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Initialize TabNetClassifier
clf = TabNetClassifier(optimizer_fn=torch.optim.Adam,
                       optimizer_params=dict(lr=1e-3),
                       scheduler_params={"step_size":100, # how to update learning rate
                                         "gamma":0.9},
                       scheduler_fn=torch.optim.lr_scheduler.StepLR,
                       mask_type='entmax', # "sparsemax"
                       device_name=device)

# Fit the model on the training data
clf.fit(X_train_pca, y_train,
        eval_set=[(X_test_pca, y_test)],
        eval_name=['test'],
        eval_metric=['accuracy'],
        max_epochs=25,
        patience=50,
        batch_size=15,
        virtual_batch_size=8,
        num_workers=0,
        drop_last=False)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# For the 1D-CNN Model
# Predicting the test set results
y_pred_cnn = model.predict(X1_test)
y_pred_cnn = (y_pred_cnn > 0.5).astype(int)

# Calculate metrics
accuracy_cnn = accuracy_score(y_test, y_pred_cnn)
precision_cnn = precision_score(y_test, y_pred_cnn)
recall_cnn = recall_score(y_test, y_pred_cnn)
f1_cnn = f1_score(y_test, y_pred_cnn)

print(f"1D-CNN Model - Accuracy: {accuracy_cnn:.2f}, Precision: {precision_cnn:.2f}, Recall: {recall_cnn:.2f}, F1 Score: {f1_cnn:.2f}")

# Correcting the prediction line for TabNet
y_pred_tabnet = clf.predict(X_test_pca)

# Since TabNet's predict might return predictions in a different format, ensure they're suitable for evaluation
y_pred_tabnet = y_pred_tabnet.reshape(-1)  # Reshape if necessary to ensure compatibility with y_test

# Recalculate the metrics for TabNet with the corrected predictions
accuracy_tabnet = accuracy_score(y_test, y_pred_tabnet)
precision_tabnet = precision_score(y_test, y_pred_tabnet)
recall_tabnet = recall_score(y_test, y_pred_tabnet)
f1_tabnet = f1_score(y_test, y_pred_tabnet)

print(f"TabNet Model - Accuracy: {accuracy_tabnet:.2f}, Precision: {precision_tabnet:.2f}, Recall: {recall_tabnet:.2f}, F1 Score: {f1_tabnet:.2f}")